# Fluentd ConfigMap - Konfiguracija za parsiranje i filtriranje logova
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: kube-system
  labels:
    app: fluentd
data:
  fluent.conf: |
    # Input - čitanje kontejner logova
    <source>
      @type tail
      @id in_tail_container_logs
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      read_from_head true
      <parse>
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    # Input - čitanje sistemskih logova
    <source>
      @type tail
      @id in_tail_syslog
      path /var/log/syslog
      pos_file /var/log/fluentd-syslog.log.pos
      tag syslog.*
      <parse>
        @type syslog
      </parse>
    </source>

    # Filter - dodavanje Kubernetes metapodataka
    <filter kubernetes.**>
      @type kubernetes_metadata
      @id filter_kube_metadata
      kubernetes_url "#{ENV['FLUENT_KUBERNETES_URL'] || 'https://kubernetes.default.svc'}"
      verify_ssl "#{ENV['KUBERNETES_VERIFY_SSL'] || true}"
      ca_file "#{ENV['KUBERNETES_CA_FILE']}"
      skip_labels false
      skip_container_metadata false
      skip_master_url false
      skip_namespace_metadata false
    </filter>

    # Filter - isključivanje health check logova
    <filter kubernetes.**>
      @type grep
      <exclude>
        key log
        pattern /healthcheck|readiness|liveness|health|ready|live/
      </exclude>
    </filter>

    # Filter - isključivanje kube-system spam logova
    <filter kubernetes.**>
      @type grep
      <exclude>
        key $.kubernetes.namespace_name
        pattern /^kube-system$/
      </exclude>
    </filter>

    # Filter - dodavanje custom polja
    <filter kubernetes.**>
      @type record_transformer
      enable_ruby true
      <record>
        cluster_name "#{ENV['CLUSTER_NAME'] || 'default'}"
        node_name "#{ENV['K8S_NODE_NAME'] || 'unknown'}"
        timestamp ${time.strftime('%Y-%m-%dT%H:%M:%S.%NZ')}
        log_level ${record.dig("log") =~ /error|Error|ERROR/ ? "error" : (record.dig("log") =~ /warn|Warn|WARN/ ? "warn" : "info")}
      </record>
    </filter>

    # Filter - parsiranje JSON logova iz aplikacija
    <filter kubernetes.**>
      @type parser
      key_name log
      reserve_data true
      remove_key_name_field false
      <parse>
        @type json
        json_parser json
      </parse>
    </filter>

    # Filter - Semaphore specifično parsiranje
    <filter kubernetes.var.log.containers.guard-*.log>
      @type record_transformer
      enable_ruby true
      <record>
        service "guard"
        component "authentication"
      </record>
    </filter>

    <filter kubernetes.var.log.containers.front-*.log>
      @type record_transformer
      enable_ruby true
      <record>
        service "front"
        component "web-ui"
      </record>
    </filter>

    <filter kubernetes.var.log.containers.controller-*.log>
      @type record_transformer
      enable_ruby true
      <record>
        service "controller"
        component "orchestration"
      </record>
    </filter>

    # Output - slanje na Elasticsearch
    <match kubernetes.**>
      @type elasticsearch
      @id out_es
      @log_level info
      include_tag_key true
      host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
      port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
      scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME'] || 'http'}"
      user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
      password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
      logstash_format true
      logstash_prefix "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX'] || 'k8s-logs'}"
      logstash_dateformat %Y.%m.%d
      type_name "_doc"
      include_timestamp true
      reconnect_on_error true
      reload_on_failure true
      reload_connections false
      request_timeout 15s

      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.system.buffer
        flush_mode interval
        retry_type exponential_backoff
        flush_thread_count 2
        flush_interval 5s
        retry_forever false
        retry_max_interval 30
        chunk_limit_size 2M
        queue_limit_length 8
        overflow_action block
      </buffer>
    </match>

    # Output - Prometheus metrics
    <source>
      @type prometheus
      @id in_prometheus
      bind 0.0.0.0
      port 24231
      metrics_path /metrics
    </source>

    <source>
      @type prometheus_monitor
      @id in_prometheus_monitor
    </source>

    <source>
      @type prometheus_output_monitor
      @id in_prometheus_output_monitor
    </source>
